{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45f1328c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open('D:/Jupyter_Notebook/project 2/vietnamese-stopwords-dash.txt',encoding=\"utf-8\") as f:\n",
    "#     content = f.readlines()\n",
    "# # you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "# li = [x.strip() for x in content]\n",
    "# print(li)\n",
    "          \n",
    "with open('D:/Jupyter_Notebook/project 2/vietnamese-stopwords-dash.txt',encoding=\"utf-8\") as f:\n",
    "    stopwords = [line.rstrip() for line in f]\n",
    "stopwords\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40154556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Jupyter_Notebook\\\\project 2\\\\Test'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import gensim\n",
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "import pickle\n",
    "import os \n",
    "dir_path = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "dir_path = os.path.join(dir_path, 'Test')\n",
    "# '/Users/macos/Desktop/Github/NLP/Text Classifier'\n",
    "# Load data from dataset folder\n",
    "# VNTC-master/Data/10Topics/Ver1.1/Train_Full\n",
    "# VNTC-master/Data/10Topics/Ver1.1/Test_Full\n",
    "def remove_stopwords(line):\n",
    "    tokens = line.split(\" \")\n",
    "    tokens_filtered= [word for word in line if not word in stopwords]\n",
    "    return (\"\").join(tokens_filtered)\n",
    "\n",
    "def get_data(folder_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    dirs = os.listdir(folder_path)\n",
    "    for path in dirs:\n",
    "        file_paths = os.listdir(os.path.join(folder_path, path))\n",
    "        for file_path in tqdm(file_paths):\n",
    "            with open(os.path.join(folder_path, path, file_path), 'r', encoding=\"utf-16\") as f:\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                lines = gensim.utils.simple_preprocess(lines)\n",
    "                lines = ' '.join(lines)\n",
    "                lines = ViTokenizer.tokenize(lines)\n",
    "                lines = remove_stopwords(lines)\n",
    "\n",
    "                X.append(lines)\n",
    "                y.append(path)\n",
    "#             break\n",
    "#         break\n",
    "    return X, y\n",
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "064aefe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19688\\809130469.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_test/train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data_test/train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19688\\5337449.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimple_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[1;31m# keep undecoded input until the next call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dir_path, 'data_test/train')\n",
    "X_data, y_data = get_data(train_path)\n",
    "test_path = os.path.join(dir_path, 'data_test/train')\n",
    "X_test, y_test = get_data(test_path)\n",
    "\n",
    "pickle.dump(X_test, open('data_test/X_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open('data_test/y_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6d8a63dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mo_hiểm rng đa mi cuộc hnh_quân khm_ph thc sng_mù ẩn mình trong cnh rng đa mi hm_thuận bắc bình thuận bt_ngn l h thủy_điện đa mi đẹp nh một nng công_chúa ngọn thc sng_mù hùng_vĩ cao_ngất uốn_lợn nh con rng bc khổng_l xuyên rng vo thc sng_mù tri đã về chiều khi chúng_tôi đến đợc h thủy_điện đa mi rộng ha vi rất nhiều hòn đảo nhỏ đẹp nh bức tranh_thủy mc dần hiện ra trong nh hong_hôn huyền_ảo ni lu_trú đêm đầu_tiên của chúng_tôi l khch_sn ngn sao sân_bay dã_chiến của nh_my thủy_điện vi tất_cả dịch_vụ phải tự lo đến thủy_điện nhng ni h tri li không có điện đêm xuống bốn bề tối đen nh mực la bùng lên bất_ng hoi nhỡng bí_th chi_đon xã đa mi cùng một nhóm thanh_niên xã vợt hn km đng đèo vo thăm lần đầu_tiên có đon thnh_phố li đêm đó hay tin bọn mình rủ nhau đi liền cc bn cho biết li ca tiếng ht vang theo tiếng đn guitar chập chùng đêm rng lm ấm lòng cả khch lẫn chủ tầng thc sng_mù tri t_m sng tiếng chim hót véo_von gọi mọi ngi thức_giấc một nhóm đi tắm h buổi sng chuẩn_bị sức_khỏe cho một hnh_trình xuyên rng nhóm khc thì chy bộ khi_động đôi chân hnh_l phải thật gọn_nhẹ thông_bo đa ra chuẩn_bị cho cuộc khm_ph thc sng_mù cuộc hnh_quân xuyên rng vo thc khoảng km theo đng_mòn th sức những đôi chân ngó xuống l vực sâu hun_hút tôi theo ton hng_dẫn băng con đng khc tìm lối xuống chân thc dây chuyên_dụng chỉ đủ l tay_vịn xuống đợc lng_chng thc không giống những thc hùng_vĩ khc thc sng_mù mang một nét rất riêng hai tầng thon_thả đổ theo khe núi hẹp cao_ngất nh con rng bc khổng_l c_chng cả những ngi dẫn đng cho biết đi vo mùa ma hi_nc sẽ tung bụi mù nên thc còn đợc gọi tên rất lãng_mn thc ma_bay lc rng vẫn cha tìm ra lối đi xuống chân thc an_ton cả đon định bỏ_cuộc thì anh hong quang_vinh ngi tng tham_gia khảo_st thiết_kế xây_dựng nh_my thủy_điện đa mi v đã tìm ra ngọn thc ny vẫn quyết_tâm đi tìm chân thc có một đng khc xuống chân thc v về li đng mi sẽ ngắn hn nhng nguy_hiểm gấp nhiều lần anh_nh ngi dẫn đng địa_phng cho biết đon chia_tay số đông đi về lối cũ lối mòn nhiều năm ri không ngi đi đã bị l cây khô phủ mất chúng_tôi cứ thế tuột theo triền núi tôi học đợc bi_học đi rng đầu_tiên t anh vinh tìm cây còn ti bm vo cây khô l ri xuống vực toi_mng đấy trc dòng suối chia thnh hai nhnh anh vinh đi một hng tôi v khôi theo ngi dẫn đng đi một hng đi một đon chỉ còn thấy chiếc giỏ đựng dây anh anh đeo giữa suối gọi to chỉ nghe tiếng đp trả âm_thanh vang_vọng chúng_tôi bắt_đầu hoảng tiếng thc đổ nghe ầm_ầm cũng gần lắm đi tiếp về chân thc sau đó tìm đng tr_về khôi bảo thôi cứ phó_mặc số_phận xem sao sợ nhất l lc trong ha rng đa mi mênh_mông ny chúng_tôi thống_nhất xuôi theo dòng nc tr ra gần đến ngã ba chỗ gặp suối thấp_thong bóng ngi đi đo con dúi đang chuẩn_bị bc chân lên b thì bóng o đỏ của anh_nh xuất_hiện hai đứa th_pho m mặt méo_xẹo thì ra đon đng đi lên chân thc rất hiểm_tr_anh đã để chúng_tôi li có thêm một tầng thc thứ ba nữa nhng rất nguy_hiểm cả_thảy thc cao hn anh vinh cho biết tri đã tối_sầm một cn ma rng trút xuống trùm túi my_ảnh sổ_sch vo bao nilông tôi đi trong ma cả ngi lấm_lem bùn đất tôi xuất_hiện trên chiếc xe_ôm tr ra điểm hẹn'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c732d664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trường đại_học bách_khoa hà_nội'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger\n",
    "\n",
    "ViTokenizer.tokenize(u\"Trường đại học bách khoa hà nội\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
